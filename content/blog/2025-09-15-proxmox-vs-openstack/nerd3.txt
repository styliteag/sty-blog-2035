# Cloud ist Netzwerk - Proxmox & OpenStack im Vergleich | Teil 3

https://www.youtube.com/watch?v=4QTQfvmRTeA

## Intro

Im 3. Video unseres kleinen Proxmox OpenStack Vergleichs unterhalten wir uns uber Netzwerke, Storage, Backup und Infrastructure ist Code.

Ich hab hier in den ersten Videos schon ausgeführt, dass in OpenStack die Projekte mit eines der fundamentalsten logischen Bausteine sind. Sie sind virtuell gegeneinander quasi völlig abgeschottete Rechenzentren. Eine wichtige Voraussetzung dafür?

## Cloud is Network

Die Verlockung bei vielen ist groß zu sagen, netzwerk nicht so wichtig. Ein paar Wildlands im Switch das war es.

Nein. Eigentlich ist es genau anders herum. Cloud ist Netzwerk. Der Rest ist überspitzt formuliert, nur ein süßes Eton dazu. Und deshalb könnten gerade beim Thema Netzwerk Proxmox als Virtualisierungsplattform und OpenStack als Cloud-Plattform nicht weiter voneinander entfernt sein. Lasst mich euch da mal mitnehmen.

Proxmox hat im einfachsten setup-classischen Bridges, die meist ebenso klassisch an ein Deeland in Eurer Switch-Fabric gepinnt sind. Weiß ich einer VM nun eine solche Bridge zu, ist sie auf Layer 2 in das entsprechende Netzwerk eingebunden. Dafür muss aber jeder hoste Parat konfiguriert werden. Etwas, das schon bei drei Notes durchaus fehleranfällig sein kann, wenn man diese nicht gerade auf Basis von Ensel oder ähnlich automatisiert hat. Man muss aber auch führerweise im gleichen Atemzug sagen, in den letzten Versionen ist in Punktone Netzwerk ein wahres Feuerwerkfunktionen in Proxmox dazu gekommen. Wenn auch teilweise noch relativ rudiment her und nicht forciert, und auch zum Teil noch im Beta-Status, stichwort SDN, Software Defined Networking. Die Idee hinter dieser Funktionalität ist, das Netzwerke in Zonen zu aggregieren und diesen Zonen gesammelt rechte zu geben oder zu verweigern. Dazu gehören auch geschachtelte Netzwerke wie Q&Q, WLAN in WLAN und sogar VXLAN und EVPN. Die Konfiguration eben dieser ist für Proxmox-Verhältnisse nicht ganz simpel, aber auf jeden Fall die Mühe wert zumindest, wenn man mehr als nur einfache WLAN-Trennung haben will. Und dass der Abschnitt zum Netzwerk hier so kurz ist, ist der Tatsache geschuldet, dass wir das Thema aufgrund seiner Schleungröße wirklich nur minimals an der Oberfläche erfangen. Wir werden hier auf dem Kanal allerdings eine ganze Serie zum Thema Data Center Netzwerke machen und darauf dann auch mehr eingehen. Sobald das raus ist, werden wir das da verlinken oder ihr lasst ein Abo da, dann bekommt ihr davon auch mit.

Das das Thema Netzwerke gefühlt unendlich groß ist, gilt übrigens natürlich noch viel mehr unter oben Steck. Denn dort ist das Newtchenmodul, das eben für Netzwerk zuständig ist, wahrscheinlich eines der Umfangreichsten. Alleine das Inhaltsverzeichnis der Moduldokumentation ist länger als um mancher andere Moduldokumentation insgesamt. Denn wie eben schon gesagt, Cloud ist Netzwerke. Alles andere ist ein Süßeset-On dazu. Wenn ich virtuell Ressourcen zwischen Berlin, Ost und Paris verbinden und sicherstellen möchte, dass auch wirklich nur die Ressourcen sich sehen, von denen ich will, dass sie sich sehen, dann muss ich da schon einiges einmal geben Netzwerkwerk lassen. Und auch in der Workload-Ebene wird Netzwerke ganz anders behandelt als in einer klassischen Virtualisierungsumwebung. Das fing schon damit an, dass jedes Projekt sein eigenes Software Defined Overlay Netzwerk hat oder vielmehr seine eigenen Overlay Netzwerke. Denn davon kann ich in OpenStack grundsätzlich beliebig viele anlegen und alle davon sind isoliert von sämtlichen anderen Netzwerken. Verbunden sind diese Projektnetzwerke, da nach außen hin mit einem eigenen virtuellen Router. Und dahinter steckt so unglaublich viel von der Macht von Cloudlösung wie OpenStack. Die virtuellen Maschinen sehen nur ihre eigenen Netzwerke und über den Router noch das Internet und andere Bereiche so ich will. Die Trennung in die verschiedenen Projekte bei OpenStack ist daher weit aus mehr als nun organisatorisches Einzottieren von virtuellen Maschinen in bestimmte Ordnung oder Puls. Es ist die Netzwerkseitige Isolation von etwa Projekt 1 und Projekt 2. Auch wenn die Administratoren davor die gleichen sein würden. Und wiederum, ich trenne die Workload von der Infrastruktur-Ebene. Die zentrale IT in einem Forschungsinstitut kann sich um OpenStack als Underlay kümmern und virtuell Ressourcen für ihre Fachgebiete bereitstellen. Und die können sich Projektintern alles so konfigurieren, wie sie es möchten, instantan und ohne Tickets schreiben zu müssen.

Ihr braucht den Projekt weitere internen Netzwerke? I don't care, viel Spaß!

Mehrere Projekte haben die gleiche IP-Rainscher geben?

I don't care ist in den Oberländernetzwerken. Dabei ist sich nichts. Das einzige, was mich als zentrale IT oder IT-Sicherheit interessiert, ist der Teil hier vorne. Da, wo es quasi rein und rausgeht. Denn wie schon eben gesagt, jedes Projekt ist ein eigenes virtuelles Rechenzentrum. Was ich darüber hinaus bei OpenStack habe, sind virtuelle Load-Berlandser, die ich mir Projekt konfigurieren kann. Etwa um Webdienst hoch verfügbar anzubinden. Im Maschinenraum verbirgt sich darunter zwar weiterhin nur in Hand für Strichen eine VR-Proxy, aber ich muss diesen Service nicht mehr selber in der VR konfigurieren, sondern OpenStack kümmert sich für mich darum. Standardisiert und in Kommunikation mit den anderen Ressourcen in meinem Projekt.

Ähnliches gilt für Router, die ich zwischen Netzwerken aufspannen kann. Ein ganz besonderer dürfte dabei der Router sein, der ein Projekt mit dem Außen, dem Publiknetzwerk verbindet. Denn der ist die Schnittstille zwischen meinem virtuellen Rechenzentrum und der davorliegenden physischen Infrastruktur, die von den Infrastruktur verantwortlichen. Also glaubt dabei der respektive IT-Abteilung verwaltet wird. Sei Lob formuliert, ohne den geht nichts rein und raus. An diese Router oder auch einzelne VMS kann ich dann sogenannte Floating IP-Adressen anbinden. Floating IP sind etwa die öffnigen IP-Adressen einer Organisation. Die werden dann bei IPv4 genattet, bei IPv6 gerutet, an die virtuellen Ressourcen in meinem Projekt angeheftet und so öffentlich verfügbar gemacht. Alles ohne dass die IT da etwas einstellen muss. Aber momentmal, hab ich den im ersten Video nicht noch voll munich behauptet, dass eine private Cloud eben nicht automatisch eine unkontrollierbare Schattenheit, die bedeutet?

Hab ich und stehe ich auch so. Denn genau das zeigt sich ja hier eigentlich auch. Egal, was ich im Projekt mache. Die IT-Abteilung kontrolliert wie ein Türsteher ein und ausgänger. Wenn ich keine Floating IPs per Quoter zugewiesen bekomme, kann ich keine nutzen. Und wenn er in einer Parameter Firewall Pro 25 für SMTP eingehen gesperrt ist, kann ich in meinem schnuffeligen Projekt so viele Proz öffnen wie ich will. Der kommt doch niemals einer E-Mail aus diesem Internet über Proz 25 bei mir an. Aber pro Proz öffnen.

Klar, kann ich mir in meinem Projekt eine Firewall vor M-Einrichten. Etwa mit OPN-Sense oder was er immer. Das ist aber noch nicht so ganz der Cloud-Way. Was man stattdessen macht sind Security Groups.

Wie übrigens beide, also prox machen wir so eine Umsteck ganz gut können. Security Groups sind vereinfacht ausgedrückt, rozbasierte Firewall-Regeln. Ich kann wahrscheinlich zwar seine Security Group Webserver stellen, wer die Proz 80 in 4443 und überall aus der Reichbar sind und Proz 22, also für SSH, nur für Interne IP-Adressen aus dem Bereich 198, 60, 10, 24. Dieses Security Groups kann ich dann an Logbalancer, Router oder VMS heften. Damit kann ich, wenn ich will, sogar Firewall-Regeln in einer Lea zwei Domäne schaffen. Fernsehen, Shit!

## Storage Connection

Irgendwo muss jede VM und jeder Container seine Persistenten Daten liegen haben. Sowohl Proxmox als auch OpenStack bieten hier die verschiedensten Möglichkeiten Storage anzubinden. Ganz vorne dabei dürfte heute sicherlich self sein. Auch hier muss man einfach ein paar Props an Proxmox geben. Wenn man einen Cluster mit mindestens drei Notes betreibt, kann man self-hyperconvergän quasi mehr oder weniger komplett über Proxmox wohl installieren.

Das Markt vielleicht jede überconvergännte Infrastruktur, ich die skalierungsfähigste aller Lösungen sein, aber stabil ist sie. Und wenn man einen sehr genannten Self betreiben möchte, kann ich auch ein externes Self anbinden.

Ich kann NFS anbinden. Ich kann Eisgase die Weises anbinden. Und das sind nur die Proxmox Eigenwege. Da der darunter ja quasi ein Standard der Bienen Linux liegt, kann ich auch alles andere zur Verfügung stellen, was ich unter Linux einbinden kann. Und der Proxmox sieht das dann einfach aus wie eine lokale Disk.

Bei OpenStack ist das Thema Storage, wie sollte es auch anders sein, wiederum sehr umfangreich. Und gleichzeitig irgendwie recht simpel. Und zusätzlich hat OpenStack drei Module für Speicher.

Swift für Object Storage, Sinder für Block Storage und Manila für Fall Storage. Alles, was ich über einen dieser drei Wege exponieren kann und das dürften praktisch nahezu alle heutigen Storage Lösungen sein, kann ich an OpenStack anbinden. Teilweise gibt es übrigens auch dedizierte Treiber von Hersternern, wie als etwa Huawei um OpenStack, wie er Feibelschellen an deren Ocean Store Appliances anzubinden. Große gehen raus an den Kunden, mit denen wir das gerade umgesetzt haben. Da ist also ein reches Interesse da, die alte Welt mit der neuen zu verbinden. Ab das technisch immer die beste Idee ist, lässt sich darüber diskutieren. Aber ich verstehe durchaus auch, dass man sein Storagesystem für ein paar hunderttausend Euro nicht einfach so mal eben wegwerfen will.

## Backup

Um das Thema Backup sinnvoll anzugehen, müssen wir erst mal zwei Begriffe trennen, Snapshots und Backup. Eigentlich auch raschief, aber das wird hier zu weit gehen. Ein Snapshot ist die Momentaufnahme einer VM. Den kann ich mit oder ohne Rahmen machen. Dieser Snapshot liegt saloppformuliert, einfach neben der VM auf dem Storage. Mit diesen in einer Regeln manuell angelegt Snapshots kann ich etwa ein kompliziertes Softwaretät in einer VM-Testen und Notfall zu spielen. Ein Backup hingegen ist das Persistente weg sichern, einer vollständigen Kopie der Daten. Diese Kopie kann das gesamte VMM-Mitch sein, das kann aber auch eine Kopie der wichtigsten Inhalte der VM sein.

Proxbox bietet mit dem Proxbox Backup-Server ein eigenes sehr mächtiges Tool für Backup-San. Und wie immer mit dem Fokus auf läuft einfach ein Stabil und läuft und läuft. Mit dem Proxbox Backup-Server kann man nicht nur VMS sichern und wieder herstellen, man kann die Backups auch verschlüsseln, auf Tabes sichern, ja das lohnt sich, und sogar einzelne Dateien. Das ist ganz komfortabel über die Web-Oberfläche wieder herstellen. Atmen ins, die aus der Welt der klassischen Virtualisierungsplattformen kommen, werden sich so fortwohlen. Bei OpenStack ist das Thema Backup, wie übrigens in der gesamten Cloud üblich, nicht so einfach. Im Gegenteil, das hat vor allem zwei Gründe. Zum einen wird eine Cloud in weit ausgrößere Maser, als man es klassischerweise kennt, automatisiert. Und dann versprechen wir gleich im nächsten Kapitel noch ausführlicher, wenn es um Infrastructure ist, Code geht. Wichtig ist hier, wenn ich sowohl meine Infrastruktur, also VMS, Netzwerke, Load Balance und so weiter, sofort automatisch aufbauen, als auch die Software-Pakete in meinen VMS-Automatisch die Pleure, habe ich ja, nennen wir es mal ganz allgemein skripte. Und wenn ich die habe, ist meine VM nur noch eine Art reproduzierbare Hülle, von der ich gar kein Backup mehr brauche. Klar, die Nutztaten muss ich sichern. Aber den Rest kann ich mir ja nicht nur genau so gut, sondern noch viel einfacher wieder, from scratch, aufbauen, wenn es nötig wird. Das heißt, der Schmerz ein Backup meiner VM-Hülle zu benötigen, ist mit dem Cloud-Gedanken viel, viel, viel, viel kleiner.

Der zweite Grund ist, ein VM-Snap-Shot oder Backup bringen größere Risiken mit sich, als man gemeinnin denkt. Denn ich sicherer ja einer VM-Kontext unabhängig, in der Infrastruktur ihre Daten quasi und am allerwertesten Back. Weiß ich, auch sich eine Datenbank darin, gerade in einem Atomahn-Schreibzug aufgefahren und ich damit quasi inconsistente Daten wegsichere?

Nein. Einziger Weg darum herum, ich installiere mir in die VM ein Gest Agents, der mit meiner Infrastruktur kommuniziert und beispielsweise Prozesse kurz anhält oder sonstige Checks macht. Nur gerade in der Public Cloud wollen die Kunden ja eher ungehan, dass die Infrastruktur ihrer VM sagt, was sie jetzt mit einem Betrieb tun soll. Und vor allem, wenn ich schon in einer VM-Zusatz-Soffe installieren muss, dann kann ich auch einfach direkt Backup-Soffe installieren. Aus diesem Grund ist die Philosophie in der Cloud im Grundsatz, Backup ist Aufgabe meiner Workload-Ebene, sprich meiner VM. Dafür gibt es dann dutzende Tools, hier mal exemplarisch RESTDIC, was es für Linux, Windows, Mac und BSD gibt. Persönlich verstehe ich den Ansatz der Cloud-Datives sehr gut. Ich verstehe aber auch zugegebenermaßen den Ansatz der klassischen Enterprise-Umgebung. Nicht zuletzt, weil auch im Jahr 2025 längst nicht jede Workload automatisiert installiert werden kann, oder mit wenigen Handgriffen ein Backup-Erstellweis. Der Segen der Vollständigkeit halber. Natürlich kann man auch in OpenStack über RP-Codes-Napshots einlegen, diese Volume-Propie auf einen anderen Speicher legen und damit quasi ein VM-Back-Ab erhalten. Das dann aber ohne Schedule oder Retention-Policy, also zumindest von Seiten OpenStack selber. Ich lasse hier mal ganz bewusst, dass etwas verweiste Frieza-Module außen vor. Wenn man will, kann man das natürlich auch mit einfach Skripten und Crown Jobs nachrüsten. Es gibt aber, in ein paar Jahren sicherlich getrieben, auch dadurch, dass einige klassische Enterprises sich jetzt in Richtung Private Cloud entwickeln. Einige Drittanbieter, die dieses Featuren bieten. Deren Preise sind allerdings eher oben rechts im Regal angeordnet. Wir sind hier in kleineren bis mittleren Umgebungen regelmäßig bei unteren 3-stelligen Summen pro Jahr, also pro VM. Deswegen muss ich ganz klar sagen, wenn es neben dem Installationsaufwand ziehe zweites Video, für umsteiger eine Archäle sehne bei oben, der gibt, dann ist es ganz klar das Back-Up. Und daher hier noch bei Hut-Up an Proxbox, die zwar auch in diesem Kapitalin geringeren Redeanteile erfahren haben, aber das einfach, weil es läuft. Zumindest, wenn man das Prinzipbedingte Risiko des Back-ups der VM-Hülle außen vorlässt.

## IaC

Einer der Grundgedankt und von Cloud ist, Standard Rise Everything, Automat everything. Nur so kann ich skalieren, oder was dachtet ihr wie AVS so krass wachsen konnte?

Die Standardisierung und Automatisierungsanforderung geilt natürlich lange primär für die unterliegende Hardware, aber mittlerweile auch für die virtuelle Infrastruktur darüber. Eine meiner Kollegen sagt immer so schön, wenn ich bei einer produktiven Cloud Umgebung auf die GUI muss, bin ich im State verzweifelt angekommen. Und ganz falsch liegt er damit meiner Meinung nach nicht. Der mittig meine virtuelle Infrastruktur standardisieren und automatisieren kann, braucht es drei Dinge. Erstens, Standardisierte möglichst leicht gewichtige Betriebssystem-Images. Zweitens, eine Möglichkeit diesen Image-Komfortabler und automatisiert von Host aus Grundkonfiguration wie, Routpasswort, SSH Key, Host Damps usw. zu inizieren. Und drittens die Möglichkeit, meine gesamte Infrastruktur wie er Code zu verwalten.

Das Erste ist natürlich völlig unabhängig davon, ob ich ein Proxmox OpenStack was auch immer benutze. Von jeder großen Linux-Distribution gibt es Cloud Images. Und auch bei Windows gibt es mittlerweile Anleitung, wie man sich Cloud Images erstellen kann.

Das zweite Feature lässt sich heute über Cloud-Inditrispektive bei Windows Cloud-Base-Indit erreichen. Das sind einfach Software-Pakete, die im Cloud-Image abgelegt werden, beim ersten Boot die notwendigen Parameter von der Infrastruktur erhalten und darauf basieren, dann das Betriebssystem-Initialkrank figurieren. Ohne das müsste hier ein, was was ich, Ubuntu für alle User dieser Welt mit einem Standardhost, der im Standard Passwort ausgeliefert werden. Beide Lösungen, also Proxmox und OpenStack, können wunderbar mit Cloud-Indit umgehen und ihren Gastsystemen Parameter übergeben. Hier mal an Beispiel von Proxmox. Ein wenig komplizierter wird es bei der Konfiguration meiner virtuellen Infrastruktur und hier trennt sich die Spräu vom Weizen. Bei OpenStack ist alles ein Apikoll. Oder auch das Webfront and Horizon, oder vielleicht bei demnächst der potenzielle Nachfolger Skyline, sind nur Module, die Apikolls ausführen. Da ich alles wie er Apisteuern kann, kann ich statt des Webfronts enden, mein Projekt auch über Tools wie Terraform oder mittlerweile eher dem freien Vorgobentofu verwalten. Ich kann damit via Code-Netzwerk anlegen, würde alle Maschinen die pläuen, oder Floating-App-Stores-Sourcenen zufügen. Und bin plötzlich im Bereich Infrastructure ist Code angekommen. Meine gesamte Infrastruktur der Workload-Ebene liegt in Code. Und das ist nicht nur ein Spielzeug, sondern schafft mehr ungeahnte neue Möglichkeiten. Ich kann Infrastrukturen und Parallel in Team entwickeln. Meine Kollegin kümmert sich etwa im Netzwerker, einen Androm, VMS und einen dritter um die Security Groups. Ich kann Beschreibung meiner Infrastruktur komplett in Code-Visionieren, etwa über Git. Ich kann meine Infrastruktur über Linting Tools formal auch Fehler überprüfen, etwa OpenWeb Server auch die richtigen Security Groups zu gewesen hat. Oder auch bei dem Namenskonzept entspricht. Ich kann meine Infrastruktur kopieren und bin weniger Sekunden neu ausrollen, etwa wenn ich für Testzwecke ein Clown meiner DMZ aufbauen möchte. All das kann ich, weil ich auf Workload-Ebene alles in OpenStack über die AR besteuern kann.

Mein Kollege Matthias hat auf den letzten Chemnizalinostang ein Vortrag zugehalten, den ich euch mal unten verlinken werde. Bei Proxmox geht es zwar auch ein Terraform-Pro weiter. Der Essen beim Vergleich zu OpenStack und auch AVS oder Edge erheblich-sperrlicher. Wiederum kein Hate. Bitte behaltet im Hinterkopf, dass die Idee von Proxmox eine Virtualisierungsplatform ist, keine Cloudplatform. Das Proxmox also negativ anzukreiten, ist sich wie bei Motorrad darüber zu beschweren, dass es keine Klimaanlage auf der Fahrerseite gibt. Kann man machen?

## Hardware Resources

Ein Teacher von OpenStack läuft einfach außer Konkurrenz. Ich will es hier trotzdem noch einmal als eine Art Notabine einfügen.

OpenStack hat, wie wir hier in der Karte schon gezeigt haben, gefühlte 17,5 Millionen Unterprojekte. Ein sehr cooles davon ist Ironic, bei dem ich meinen Anwendern bare Metalressourcen fast genauso wie virtuelle Maschinen zur Verfügung stellen kann. Wir könnte ich das gebrauchen, immer da wo virtuelle Maschinen zu viel Overhead fressen, etwa beim Hyperforms Computing oder Maschinenlearning, also unserer Welt, oder auch bei der Datenbankanbindung. Das heißt, ich habe mit Ironic quasi etwas vor einfach runtergebrochen, die Performance von bare Metalmaschinen gepaart mit der Flexibilität einer Cloud Umgebung. Kennen Wunder also, dass etwa das Zian sein riesigen HPC Cluster genau so verwaltet.

## Conclusion

Proxmox und OpenStack bedienen an der Felder.

Ich hoffe sehr, dass das klar geworden ist. Mit einem kleinen Team einfach einer Satz für E6E und wie es wir sucht, wird wahrscheinlich regelmäßig völlig zurecht zu Proxmox greifen. Und wird es mit aller Wahrscheinlichkeit nicht bereuen.

Wer allerdings Workloads für Teams mit unterschiedlichen Kompetenzen abbilden muss, verschiedene Sicherheitslevel oder Standorte hat oder gar bei Metalressourcen anbieten möchte, der wird vielleicht überlegen sich zu einem PrivateCloud-Anbieter vorzuentwickeln und dabei eventuell den Schritt zu OpenStackwagen. Leicht wird der nicht, plus wir sei verraten, aber er kann sich definitiv lohnen.

Und wie schon im ersten Video gesagt, gerne unterstützen wir euch dabei. Einfach auf einen der Links unten klicken und Termin vereinbaren.

Und da wir hier gerade in einem Bereich der Werbung irgendwo sind, wir suchen natürlich auch immer Hochleistungsnörd und Nörden in Speedy Lust haben, mit uns geile Infrastrukturen aufzubauen. Von Virtualisierung über PrivateCloud bis hin zu ausgewachsenen HPC und AI-Cluster.

Und falls du bisher technisch nur ein Junior oder Mittelleistungsnörd bist, ist das auch nicht schlimm.

Das Wissen bekommen wir dir schon beigebracht. Viel wichtiger ist für uns, dass du einfach Bock hast, Dinge zu tun und dich immer weiter zu bilden. Alle Infos haben wir dir unten verlinkt.

So, das war's erstmal. Macht's gut.

Ciao.

