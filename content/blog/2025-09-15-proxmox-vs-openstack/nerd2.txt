# Cluster, Nutzer & GPU im Deep-Dive - Proxmox & Openstack im Vergleich | Teil 2

https://www.youtube.com/watch?v=NiRUc6Y3-90

## Intro

Im ersten Video hatten wir uns ja darauf konzentriert einmal Proxmox und OpenStack High Level gegenüberzustellen. Und wir haben festgestellt, Proxmox ist ein klassischer Virtualisierer und OpenStack der Unterbau für eine Private Cloud. Heute werden wir mit dem technischen DeepDive beginnen und vier große Themen abarbeiten. Installation und tägliche Arteninstration, Clustering, Nutzer und Rechteverwaltung und das Thema GPU.

## Installation

Fangen wir aus Atmen Sicht ganz vorne an, Installation und die tägliche Administration. Die Installation von Proxmox ist easy und straightforward, das kann man ja anders sagen. Da gibt es im Jahr 2025, wenn man nicht irgendwelche Sonderlohn versucht, neidlose 5 von 5 Sternen.

Mein Letzter die ISO Datei auf ein USB-Stick, der dann das Angepasste derbieren und alle notwendigen Quellen enthält, schließt einen Monitor an den Host an, klickt sich im wahrsten Sinne des Wortes durch die Installation. Start neu, lockt sich über das Webfront ed ein und kann dann nach 10-15 Minuten ein fertiges Proxmox nutzen.

Lokalen Speicher auswählen, eventuell noch konfigurieren, sofern man das nicht schon während der Installation gemacht hat, ISO hochladen und dann kann die erste VM oder der erste Container installiert werden. Fertig! Mehr noch!

Die wichtigsten Infos und Metrien zu jeder VM bzw. jedem Container findet man so grafisch aufbereitet, dass man in Kleistumgebung fast schon versucht ist, auf einen Monitoring zu verzichten. Und wer sich da nicht zusammenklicken will, kann Proxmox natürlich auch via Ensebel und Co. quasi voll automatisiert werden. Und auch die tägliche Ateminstration geht in Proxmox super simpel von der Hand. Lockt man sich mit Ateminstrativen rechten ein, kann man sogar über die Oberfläche direkt Updates des Hosts machen. Zumindest in der Thürie bis hin zu kompletten Major Release Upgrades. Bei OpenStack hingegen muss man von Anfang an ein wenig mehr Hörnspalls investieren. Ein einem Nachmittag OpenStack zu installieren geht schon, wenn man weiß, was man tut, wird man dabei in aller Regel auch, wenn man weiß, was man tut, eher nicht machen. Das hat weniger damit zu tun. Dass die Entwickler hinter OpenStack doof sind, sind sie nicht. Sondern damit, dass OpenStack darauf ausgelegt ist, hunderte oder gar tausenden Notes in mehreren Rechenzentren über verschiedene Regionen dieser Welt hinweg zu verwalten. Und damit gehen halt viele, oder eher sehr viele Optionen einher. Man muss sich einfach klar machen, wenn Proxmox eine Cessna Skyhawk ist, dann ist OpenStack ein Airbus A380. Beginnen wird man bei der OpenStack Installation sogar einen Schritt vor der eigentlichen OpenStack. Und wird quasi daneben Infrastruktur aufbauen. Da liegt dann das Monitoring. Da liegen die OpenStack Controller Notes. Da liegt dann eine Netbox als Single Source of Truth. Dann kommt noch das Storage etwa mit Seth. Das heißt, ich habe mit Quorum in der Regel schon sechs bis acht physische Notes verbraten, bevor die erste virtuelle Maschine überhaupt läuft. Und erst dann fallen die eigentlichen Computer Notes, auf denen die VMS laufen.

Natürlich bekomme ich auch OpenStack irgendwie hyper convergent auf die drei Notes geprügelt. Aber so ganz im Sinne der Erfinder ist das halt nicht. Und damit zeigt sich auch schon, warum ich im ersten Video sagte, dass aus unserer Sicht OpenStack in vielen Fällen gar kein Sinn ergibt, wenn man 30 Wirtuelle Maschinen fährt. Der Nutzen von OpenStack kommt häufig mit der Skalierung der Infrastruktur. Denn der administrative mehr Aufwand von 1.000 zu 2.000 Wirtuellen Maschinen ist da minimal. Mehr Hardware kaufen, einbauen, die pläuen sind vollerweise noch ins Monitoring, das war's in Grundsatz.

## Clustering, Projects, and VM Flavors

Clustering beschreibt die Tatsache, dass man mehrere in der Regel 3 oder mehr physische Notes zu einem Verbund zusammenschließt. Und das will ich unabhängig von meiner Software quasi immer machen. Nicht nur, weil ich damit skalieren kann, sondern auch weil ich mich überhaupt damit erst unabhängig von der Hardware einer Note mache. Sonst habe ich damit im Server-Jahren-Single-Point-Aferia. Fällt die Note aus, sind auch alle Maschinen darauf tot. Und zwar, bis der Hardware-Satz da ist. Viel Spaß bei sowas.

Bei Proxmox geht der Aufbau eines Clusters wieder nach Razfrats. 3 Notes mit möglichst identischer Hardware installieren, dem Clustering-Menü folgen und knapp von gut 5 Minuten hatten aus 3 einzelnen Notes ein HA-Cluster mit Quorum gebaut.

Und falls du dich jetzt fragst, warum für ein Quorum mindestens 3 Notes notwendig sind, schau dir gerne das verlinkte Video an.

Bei unserem Proxmox-Cluster kann ich jetzt nicht nur beim erstellen einer VM-Bestimmung auf welcher Note sie läuft, sondern diese auch live und ohne Ausfälle von einer Note zunächst migrieren.

Ich kann also dem noch festlegen, dass wenn eine Note garantiert ausgefallen ist, vor allem davon auf anderen Notes neu gestartet werden. Das funktioniert unsere Erfahrung nach in aller Regel einwandfrei. Ist aber im Grunde auch schon alles, was ich bei Proxmox selber zu dem Thema an Funktionalität bekomme.

Fortgeschrittenes Features wird war Affinitätsgruppen, Ken Proxmox zumindest stand heute nicht. Und ich lasse dir mal ganz bewusst plag ins wie ProxLB außen vor, weil ich leider nicht zu der Qualität sagen kann.

Dann bin ich hier nochmal kurz aus dem Edit. Wir wollen hier keine Fake News verbreiten. Während der Produktion des Videos hat Proxmox, wie sollte es auch anders sein, Version 9 released, in der es Affinitätsgruppen noch doch gibt.

So, zurück ins Video. Kurz exkurs. Affinitätsgruppen sind wie Magnete, bei denen ich dafür sorgen kann, dass ich vor M's gegenseitig auf einem Host anziehen oder abschließen. Letzteres würde ich hier vermachen, wenn ich einen hoch verfügbaren Webservor war auf zwei Freimsbetreiber. Dann möchte ich ja sinnvollerweise nicht, dass die auf dem gleichen Host liegen, so dass dieser Host nicht einmal ganz kurz zu einem Single-Point-of-Ferrier wird. Schiebe ich also eine VM, der gleiche negativen Affinitätsgruppen auf einen Host, wird die andere davon wegmigriert. Und zwar automatisch.

Was ich unser Proxmox allerdings build in tun kann, ich kann mit HA-Gruppen festlegen, dass eine VM nur auf bestimmten Notes läuft oder automatisch dort hinmigriert wird. Zwei Fälle in den, das interessant sein könnte. Zum einen, unterschiedliche Hardware, die eine Note hat GPUs verbaut, die andere nicht. Und zum anderen, verschiedene Sicherheitslabelig nicht auf dem gleichen Host laufen lassen möchte. Wenn ich also klassisch die im Z und interne dienste Host-Zeitig trennen möchte, also von außen Firewall, DMZ, Firewall, Internet-Cluster, dann muss ich unter Proxmox zwei separate Gruppen aufbauen. Das soll sich mit dem Data Center Manager ändern, der ist allerdings startes heute nur in der Alpha-Version erhältlich und wirkt im Gegensatz zu den restlichen Proxmox-Produkten ein wenig überhasstet, released. Wichtig ist in dem Zusammenhang auch, auch im Cluster muss ich bei Proxmox für viele Features jede Note einzeln verwalten. Das werden wir gleich im Netzwerk etwas stärker sehen.

Bei außen Steck muss man sich erst mal fast schon Philosophisch fragen, was ist eigentlich ein Cluster. Denn im Grunde gibt es mehrere Optionen, notes zusammenzufassen. Die wichtigsten dürften Availability-Sons und Host-Agrigates sein. Ersteres sind örtliche Unterteilungen, Wertware, Brandabschnitte. Die sehen die Nutze auch und können sie aktiv ihre virtuellen Maschinen auswählen. Host-Agrigates sind eher administrative Unterteilungen, Wertware, Server-Unterschiedliche Generation oder AMD versus Intel-Hosts. Diese sehen die Nutze allerdings nicht direkt, sondern wählen sie indirekt mit dem Flavor der VM aus. Dafür kann ein Host dann auch einer quasi unbegrenzten Anzahl von Host-Agrigates zu Gordet sein, während das für Availability-Sons logischerweise nicht gilt. Neben Availability-Sons und Host-Agrigates gibt es in außen Steck die oben schon kurz angesprochenen Regions, wie man sie von etwa den Hyperscale ankennt.

Berlin, Amsterdam, Europa, China, was auch immer örologisch unterteilung ist. Was ein Regen von einer Availability-Sons unterscheidet, die Regions sind völlig unabhängige Klaster und beispielsweise Storage und Anordaten werden zwischen denen nicht von der Infrastruktur-Synkronen gehalten. Warum das? Naja, weil sonst jeder Schreibzugriff im Storage-Andalai, also bevor er der VM gemeldet würde, beispielsweise zwischen Berlin und Amsterdam hin- und her tingeln müsste. Da ist alleine die Luftlinie etwas über 575 Kilometer, was rein physikalisch bedeutet, dass die Rundlaufzeit eines jeden Pakets über Glasfaser 6 Millisikunden bedeuten würde.

6 Millisikunden Verzügerung für jeden einzelnen Storage- oder Datemangzugriff.

Sprachen wir schon über die Performance einer Tonne Granite auf einem Bobbika?

Zurück zur Umsteck. Ich habe ja gerade von VM Flay was gesprochen. Wer schon einmal mit den großen Hyperscale angearbeitet hat, kennt das sicherlich schon. Statt, dass sich für jede VM genau festlegen muss, wie viele virtuelle CPUs und Ram sie bekommt, stellt der Opem-Stack-Admin vor abgebisse Flay was, also T-Shirtgrößen zur Verfügung. Da könnte eine kleine VM namens Tiny eben 1V CPU und 500 12 Mega-Beit-Ram haben und eine große Namens XL 16V CPUs und 64 GB-Ram. Oder gerne mit GPU-Ressourcen. Der Nutzer der Cloud will dann nur noch diese Größe in seinem Projekt aus. Der Vorteil dieser Flay was für euch in Infrastruktur?

Ihr könnt sicherstellen, dass auf den jeweiligen Hosts ein CPU zur Rammverhältnis durch VMS eingehalten wird, dass zu eurem Hardware-Design passt. Und den ich plötzlich kein Ramm mehr zur Verfügung habe, während die CPU nur zu 2% ausgewitzt ist. Im Gegensatz zu Proxmox kann Opem-Stack auch Affinitätsgruppen und Anti-Affinitätsgruppen verwalten. Wenn ich also zwei redundante Elder-PvMS im HA-Cluster betreibe, kann ich über negative Affinität sicherstellen, dass die auf unterschiedlichen Hosts laufen. Möchte ich hingegen sicherstellen, dass zwei VMS auf die gleiche Hardware zu greifen kann. Stichwort Weiße 2-Zweiser, Local Storage und dafür auf den gleichen Hostlaufen leg ich eine positive Affinität fest. All das gerade besprochene wird bei Opem-Stack aus Sicht des Nutzers über ein einziges Wapfernd entgestreert. Selbst über mehrere Regionen wie etwa Berlin und Amsterdam hinweg. Und mit dem Stichwort Nutzer leiten dir direkt über zur...

## User and Permission Management

Tutten Disziplin

Der nächste für wahrscheinlich sehr viele Organisationen wichtige Punkt dürfte die Nutzer und Rechteverwaltung sein. Denn wenn ich Server-Cluster im Organisationskontext betreibe, werde ich mit großer Wahrscheinlichkeit mehr als einen Nutzer haben. Bei Proxmox kann ich hier sowohl intern Nutzer verwalten, als auch extern solche über LDAP Microsoft AD oder bei modernen Single-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal-Signal oder regelmäßig synchronisiert, so dass sie im System zur Verfügung stehen. Damit kann ich als Admin nur Nutzer oder Gruppe-Rechte für virtuelle Maschinen geben.

Ich kann die VMS, Container und Storage ist aber auch in sogenannten Pools verwalten. Das sind quasi ordner, über die ich deinem Gapul-Verschiene-Rechte an Nutzer und Nutzergruppen zu teilen kann. Die Gruppe, Marketing, könnte also die VMS in ihrem Pool vollständig verwalten dürfen, allerdings keine anderen überhaupt sehen. Die Gruppe First Level Support könnte vielleicht in alle Pools schauen und dort VMS neu starten dürfen, aber nicht neu anlegen oder die Konfiguration bestehender vor EMS oder Container ändern. Was es dabei, wie im ersten Video ja schon erwähnt, unter Proximungsbes heute leider nicht, gibt, Quotos. Wer vor EMS erstellen kann, kann vor EMS erstellen, bis der Host voll ist, oder der Storage, oder das Netzwerk. Man muss also seinen Nutzer grundsätzlich ein wenig vertrauen können. Bei oben Steck sieht das natürlich ganz anders aus. Wir hatten ja im ersten Video schon festgestellt. Als Cloud Provider darf ich meinen Nutzer nicht vertrauen. Aus diesem Grunde gibt es unter oben Steck eine viel stärkere Trennung von Nutzergruppen, nämlich über die sogenannten Projekte. Natürlich hole ich die Nutzer auch wieder aus dem L-Dab oder Deserver raus oder auch via Single Sign On. Aber das ist eben nur ein Teil, den die Nutzergruppen werden verschiedenen Rollen in den Projekten zu gewiesen. Und jedes Projekt hat ein komplettes Set, eine Einstellung und Quotos etwa die maximale Anzahl der virtuellen CPUs, die maximale Menge an Rahmen, die maximale Anzahl an Snapshots, und auch die maximale Anzahl, interner Netzwerke, Load Balance und Sicherheitsgruppen, über die wir im nächsten Video ausführlich sprechen werden. Ich kann bei der Projektkonfiguration sogar so weit gehen, dass es bestimmte VM-Flavours in einzelnen Projekten gar nicht gibt, etwa, weil es in der DMZ niemals GPU-Ressourcen brauchen wird. Oder, weil Azubis um zu ihrer Ausbildung keine VMs mit 256 GB RAM benötigen.

## GPU Computing

zu benötigen haben. Aber wo GPU? Ich denke im Jahr 2025 wird kaum noch jemand ernsthaft die Frage stellen, wozu es GPU Power im Server braucht. Von selbstgehosteten Large-Language Modellen oder auch spezifischeren KI-Anwendungen bis hin zu Virtual Desktop Infrastrukturen oder Render-Farm ist die Bandbreite in den letzten Jahren vor allem durch AI und Home Office quasi explodiert. Wenn man GPUs in virtuelle Maschinen einbinden gibt es tatsächlich einige Optionen. Die wichtigsten dürften das volle durchreichen, also PCA-Pair-True?

Ich will hier gar nicht soweit in die Tiefe gehen, das ganze Thema wird genug Stoff von eigenes Video sein, nur so viel. Aus Sicht des Hosts reichen wir, wenn wir eine vollständige Karte an den Gast durchreichen, ein ganzes PCI-ID-Weiß durch. Wenn wir GPUs leises, also Teile von GPUs mit VGPU oder MEG an einen Gast binden, ist dies meist eine sogenannte virtuelle Funktion für die, die sich auskennen, als Arroyo Willes grüssen. Da auch Letzteres am Ende des Tages für die Virtualisierung irgendwo ein PCI-ID-Weiß ist, kann man strefflich vor allem sagen, eine GPU in eine VM zu bringen, bedeutet ein PCI-ID-Weiß anzeigen. Und das können, im Grundsatz, beide Lösungen. Allerdings ist es auch hier wieder in Proxmox eine ekemanuelle. Man gibt eine konkrete PCI-ID-Ein. Respektive wählt sich über PCI-Resource-Mapping ein beliebiges PCI-ID-Weiß eines Typs, also hier GPU aus. Mit Letzterim kann man dann zumindest in der Theorie Live Migration machen. Zumindest sofern dem empfangenen Host auch eine GPU verbaut ist. Bei Umsteck hingegen erstellt der Atmen ein Flaver, dem GPU-Resource automatisch zugewiesen werden, etwa mit einer, zwei oder vier GPUs. Oder auch nur mit einem Slicer einer GPU. Das ist für die Nutzer in der täglichen Arbeit natürlich erheblich angenehmer. Der Vollständigkeit halber sei aber erwähnt, dass VGPU bei Nvidia ein kostenpflichtiges Feature ist und demzufolge eines Lizenzmanagers bedarf. Und das ist gar nicht so günstig. Plus alle Gäste müssen mit dem Lizenzmanager kommunizieren können, egal aus welchem Netzwerk sie kommen. MIG hingegen ist selber kostenfrei. Das gibt es allerdings nur über den großen AI-Data-Statt-GPUs. Und da sind schon die Karten nicht so günstig.

## Conclusion

Ihr seht, es gibt sowohl bei der Installation als auch in der Akministration einige Unterschiede zwischen Proxmox und OpenStack. Noch mal, ist eines davon besser?

Nein, den beide Bedienen anderer UseCases. Und das wird noch vielmehr klar im dritten Video, wenn wir uns über das Thema Netzwerk unterhalten. Für heute war es das aber erst mal. Wir sehen uns nächste Woche.

Ciao!

